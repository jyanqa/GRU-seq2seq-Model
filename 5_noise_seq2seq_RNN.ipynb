{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "A3Bbm9MSP6Yk",
        "outputId": "c683a774-1a56-4614-c16e-3f5e948e5f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan 15 10:05:04 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuNqn2TkS1T5"
      },
      "source": [
        "## Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PBEAq9r9wMRI",
        "outputId": "e9dd1ef7-878d-4343-af29-8839b316748d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 38.3 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.62.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.10.0+cu111)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2021.10.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (3.10.0.2)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "Successfully installed sentencepiece-0.1.96 torchtext-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dfQk37UUQi2T"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm --upgrade >> /dev/null 2>&1\n",
        "#!pip install torchtext --upgrade >> /dev/null 2>&1\n",
        "!pip install spacy --upgrade >> /dev/null 2>&1\n",
        "!python -m spacy download de >> /dev/null 2>&1\n",
        "!python -m spacy download en >> /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zku7rzrTSE1j"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import spacy\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.data import Dataset, Example, Field\n",
        "from torchtext.data.iterator import BucketIterator\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torchtext.datasets import Multi30k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-rfDBpyrS7Pq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9780215-4123-4c1c-b0a2-b306755f715c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
        "\n",
        "SEED = 546\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {DEVICE}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pFrpUtp8cMPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01291f4-40c2-4395-f21b-2c3e12a790c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "0_no_noise  1_noise  2_noise  3_noise  4_noise\t5_noise  6_noise  7_noise\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "!ls '/content/drive/MyDrive/data_europarl/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfjuxu1QTtoP"
      },
      "source": [
        "#### Build vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1GPY7yEdf3pL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a64ebe-97e6-4c0b-f170-75cc507db4c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set size: 29,824\n",
            "valid set size: 996\n",
            "test set size: 987\n",
            "CPU times: user 733 ms, sys: 49.7 ms, total: 783 ms\n",
            "Wall time: 5.58 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "FR_TEXT = Field(lower=True,  tokenizer_language='fr', include_lengths=True)\n",
        "EN_TEXT = Field(init_token='<sos>', eos_token='<eos>', lower=True, tokenizer_language='en', include_lengths=True)\n",
        "train, valid, test = Multi30k.splits(exts=('.fr', '.en'),  fields=(FR_TEXT, EN_TEXT), root = '/content/drive/MyDrive/data_europarl/5_noise')\n",
        "print(f'train set size: {len(train.examples):,}')\n",
        "print(f'valid set size: {len(valid.examples):,}')\n",
        "print(f'test set size: {len(test.examples):,}')\n",
        "# print(vars(DE))\n",
        "# print(vars(EN))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PvuBC8xKTZJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76dbed75-40ad-4edd-9998-4e5f6667687f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of FR vocabulary: 10,438\n",
            "Length of EN vocabulary: 8,777\n",
            "CPU times: user 260 ms, sys: 1.24 ms, total: 261 ms\n",
            "Wall time: 259 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "MIN_COUNT = 2\n",
        "FR_TEXT.build_vocab(train, min_freq=MIN_COUNT, specials=['<unk>', '<pad>'])\n",
        "EN_TEXT.build_vocab(train, min_freq=MIN_COUNT, specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
        "print(f'Length of FR vocabulary: {len(FR_TEXT.vocab):,}')\n",
        "print(f'Length of EN vocabulary: {len(EN_TEXT.vocab):,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1-SpXqDT72P"
      },
      "source": [
        "# Model 5\n",
        "data is added noise type 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyEKiMbF8NfK"
      },
      "source": [
        "#### Encoder layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QOZS6pPqT7Ba"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size, n_layers, embedding_dropout, recurrent_dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding_dropout = embedding_dropout\n",
        "        self.recurrent_dropout = recurrent_dropout if n_layers > 1 else 0\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers=n_layers, dropout=self.recurrent_dropout, bidirectional=True)\n",
        "\n",
        "    def forward(self, input_sequences, sequence_lengths):\n",
        "        \"\"\"\n",
        "        :param Tensor[seq_len, batch_size] input_sequences\n",
        "        :param Tensor[batch_size,] sequence_lengths\n",
        "        :return Tensor[n_layers * 2, batch_size, hidden_size] h_state\n",
        "        \"\"\"\n",
        "        embedded = self.embedding(input_sequences)\n",
        "        embedded = F.dropout(embedded, p=self.embedding_dropout)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(embedded, sequence_lengths.cpu())\n",
        "        _, h_state = self.gru(packed)\n",
        "        return h_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALcFgkFzUMX3"
      },
      "source": [
        "#### Decoder layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-MMyNs5aUOcM"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size, n_layers, embedding_dropout, recurrent_dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding_dropout = embedding_dropout\n",
        "        self.recurrent_dropout = recurrent_dropout if n_layers > 1 else 0\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers=n_layers, dropout=self.recurrent_dropout)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, input_word_index, h_state_prev):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size,] input_word_index\n",
        "        :param Tensor[n_layers, batch_size, hidden_size] h_state_prev\n",
        "        :return Tensor[batch_size, vocab_size] logit\n",
        "        :return Tensor[n_layers, batch_size, hidden_size] h_state\n",
        "        \"\"\"\n",
        "        embedded = self.embedding(input_word_index.unsqueeze(0))\n",
        "        embedded = F.dropout(embedded, p=self.embedding_dropout)\n",
        "        outputs, h_state = self.gru(embedded, h_state_prev)\n",
        "        logit = self.fc(outputs.squeeze(0))\n",
        "        return logit, h_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaB7LsPWUO94"
      },
      "source": [
        "#### Sequence-to-sequence model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ttc82wRxUTuj"
      },
      "outputs": [],
      "source": [
        "class SeqToSeqNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        assert encoder.n_layers == decoder.n_layers, 'Encoder and Decoder must have the same number of reccurent layers'\n",
        "        assert encoder.hidden_size == decoder.hidden_size, 'Encoder and Decoder must have the same number of reccurrent hidden units'\n",
        "        super(SeqToSeqNet, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        self.init_h0 = nn.Linear(encoder.n_layers * 2, decoder.n_layers)\n",
        "\n",
        "    def encode(self, input_sequences, sequence_lengths):\n",
        "        h_state = self.encoder(input_sequences, sequence_lengths)\n",
        "        h_state = self.init_h0(h_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
        "        h_state = h_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
        "        return h_state\n",
        "\n",
        "    def sort_batches(self, dest_sequences, dest_lengths, h_state):\n",
        "        sorted_dest_lengths, sorted_indices = torch.sort(dest_lengths, dim=0, descending=True)\n",
        "        sorted_dest_sequences = dest_sequences[:, sorted_indices]\n",
        "        h_state = h_state[:, sorted_indices, :]\n",
        "        # We won't decode at the <eos> position, since we've finished generating as soon as we generate <eos>.\n",
        "        # So, decoding lengths are actual lengths - 1\n",
        "        sorted_decode_lengths = (sorted_dest_lengths - 1).tolist() \n",
        "        return sorted_dest_sequences, sorted_decode_lengths, h_state\n",
        "\n",
        "    def decode(self, h_state, sorted_dest_sequences, sorted_decode_lengths, tf_ratio):\n",
        "        batch_size, last = sorted_dest_sequences.size(1), None\n",
        "        logits = torch.zeros(max(sorted_decode_lengths), batch_size, self.decoder.vocab_size).to(self.device)\n",
        "        for t in range(max(sorted_decode_lengths)):\n",
        "            batch_size_t = sum([l > t for l in sorted_decode_lengths])\n",
        "            if last is not None:\n",
        "                if np.random.rand() < tf_ratio:\n",
        "                    input_word_index = last[:batch_size_t] # in_ [batch_size,]\n",
        "                else:\n",
        "                    input_word_index = sorted_dest_sequences[t, :batch_size_t] # in_ [batch_size,]\n",
        "            else:\n",
        "                input_word_index = sorted_dest_sequences[t, :batch_size_t] # in_ [batch_size,]\n",
        "            logit, h_state = self.decoder(input_word_index, h_state[:, :batch_size_t, :].contiguous())\n",
        "            # logit: [batch_size, vocab_size] - h_state: [n_layers, batch_size, hidden_size]\n",
        "            logits[t, :batch_size_t, :] = logit\n",
        "            last = torch.argmax(F.softmax(logit, dim=1), dim=1) # [batch_size,]\n",
        "        return logits\n",
        "    \n",
        "    def forward(self, French_sequences, French_lengths, dest_sequences, dest_lengths, tf_ratio):\n",
        "        \"\"\"\n",
        "        :param Tensor[seq_len, batch_size] French_sequences\n",
        "        :param Tensor[batch_size,] French_lengths\n",
        "        :param Tensor[seq_len, batch_size] dest_sequences\n",
        "        :param Tensor[batch_size,] dest_lengths\n",
        "        :param float tf_ratio\n",
        "        :return Tensor[max(decode_lengths), batch_size, vocab_size] logits\n",
        "        :return Tensor[seq_len, batch_size] sorted_dest_sequences\n",
        "        :return list[max(decode_lengths) - 1] sorted_decode_lengths\n",
        "        \"\"\"\n",
        "        h_state = self.encode(French_sequences, French_lengths)\n",
        "        sorted_dest_sequences, sorted_decode_lengths, h_state = self.sort_batches(dest_sequences, dest_lengths, h_state)\n",
        "        logits = self.decode(h_state, sorted_dest_sequences, sorted_decode_lengths, tf_ratio)\n",
        "        return logits, sorted_dest_sequences, sorted_decode_lengths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzVIUeL2cAsz"
      },
      "source": [
        "#### Training routines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5VPQdzdrddUu"
      },
      "outputs": [],
      "source": [
        "class AverageMeter:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def reset(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def update(self, value, n=1):\n",
        "        self.value = value\n",
        "        self.sum += value * n\n",
        "        self.count += n\n",
        "        self.average = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "a4aTFulSfGTf"
      },
      "outputs": [],
      "source": [
        "def accuracy(outputs, target_sequences, k=5):\n",
        "    batch_size = outputs.size(1)\n",
        "    _, indices = outputs.topk(k, dim=1, largest=True, sorted=True)\n",
        "    correct = indices.eq(target_sequences.view(-1, 1).expand_as(indices))\n",
        "    correct_total = correct.view(-1).float().sum()  # 0D tensor\n",
        "    return correct_total.item() * (100.0 / batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hCsp-2Fvb_li"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "\n",
        "    def __init__(self, model, optimizer, criterion, train_iterator, valid_iterator):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.train_iterator = train_iterator\n",
        "        self.valid_iterator = valid_iterator\n",
        "\n",
        "    def clip_gradients(self, grad_clip):\n",
        "        if grad_clip is not None:\n",
        "            for group in self.optimizer.param_groups:\n",
        "                for param in group['params']:\n",
        "                    if param.grad is not None:\n",
        "                        param.grad.data.clamp_(-grad_clip, grad_clip)\n",
        "\n",
        "    def adjust_lr(self, shrink_factor=0.9, verbose=True):\n",
        "        if verbose:\n",
        "            print(\"\\nDecaying learning rate.\")\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = param_group['lr'] * shrink_factor\n",
        "        if verbose:\n",
        "            print(\"The new learning rate is %f\\n\" % (self.optimizer.param_groups[0]['lr'],))\n",
        "    \n",
        "    def adjust_tf(self, tf_ratio, shrink_factor=0.9, verbose=False):\n",
        "        tf_ratio = tf_ratio * shrink_factor\n",
        "        if verbose:\n",
        "            print(\"The teacher forcing rate is %f\\n\" % (tf_ratio,))\n",
        "        return tf_ratio\n",
        "    \n",
        "    def train_step(self, epoch, grad_clip, tf_ratio):\n",
        "        loss_tracker, acc_tracker = AverageMeter(), AverageMeter()\n",
        "        self.model.train()\n",
        "        progress_bar = tqdm.tqdm(enumerate(self.train_iterator), total=len(self.train_iterator))\n",
        "        for i, data in progress_bar:\n",
        "            # if isPrinted == False:\n",
        "            #     print(data.French)\n",
        "            #     print(data.English)\n",
        "            #     isPrinted = True\n",
        "            # print(len(data.French))\n",
        "            logits, sorted_dest_sequences, sorted_decode_lengths = self.model(*data.src, *data.trg, tf_ratio=tf_ratio)\n",
        "            sorted_dest_sequences = sorted_dest_sequences[1:, :] # Since we decoded starting with <sos>, the targets are all words after <sos>, up to <eos>\n",
        "            logits = nn.utils.rnn.pack_padded_sequence(logits, sorted_decode_lengths).data # Remove paddings\n",
        "            sorted_dest_sequences = nn.utils.rnn.pack_padded_sequence(sorted_dest_sequences, sorted_decode_lengths).data # Remove paddings\n",
        "            loss = criterion(logits, sorted_dest_sequences)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.clip_gradients(grad_clip)\n",
        "            optimizer.step()\n",
        "            loss_tracker.update(loss.item(), sum(sorted_decode_lengths))\n",
        "            acc_tracker.update(accuracy(logits, sorted_dest_sequences), sum(sorted_decode_lengths))\n",
        "            loss_, ppl_, acc_ = loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "            progress_bar.set_description(f'Epoch: {epoch+1:02d} -     loss: {loss_:.3f} -     ppl: {ppl_:.3f} -     acc: {acc_:.3f}%')\n",
        "        return loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "    \n",
        "    def validate(self, epoch):\n",
        "        loss_tracker, acc_tracker = AverageMeter(), AverageMeter()\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            progress_bar = tqdm.tqdm(enumerate(self.valid_iterator), total=len(self.valid_iterator))\n",
        "            for i, data in progress_bar:\n",
        "                logits, sorted_dest_sequences, sorted_decode_lengths = self.model(*data.src, *data.trg, tf_ratio=0.)\n",
        "                sorted_dest_sequences = sorted_dest_sequences[1:, :]\n",
        "                logits = nn.utils.rnn.pack_padded_sequence(logits, sorted_decode_lengths).data\n",
        "                sorted_dest_sequences = nn.utils.rnn.pack_padded_sequence(sorted_dest_sequences, sorted_decode_lengths).data\n",
        "                loss = criterion(logits, sorted_dest_sequences)\n",
        "                loss_tracker.update(loss.item(), sum(sorted_decode_lengths))\n",
        "                acc_tracker.update(accuracy(logits, sorted_dest_sequences), sum(sorted_decode_lengths))\n",
        "                loss_, ppl_, acc_ = loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "                progress_bar.set_description(f'Epoch: {epoch+1:02d} - val_loss: {loss_:.3f} - val_ppl: {ppl_:.3f} - val_acc: {acc_:.3f}%')\n",
        "        return loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "    \n",
        "    def train(self, n_epochs, grad_clip, tf_ratio):\n",
        "        history = {'acc': [], 'loss': [], 'ppl': [], 'val_ppl': [], 'val_acc': [], 'val_loss': []}\n",
        "        best_loss, last_improv = np.inf, 0\n",
        "        for epoch in range(n_epochs):\n",
        "            if last_improv == 4:\n",
        "                print('Training Finished - The model has stopped improving since last 4 epochs')\n",
        "                break\n",
        "            if last_improv > 0:\n",
        "                self.adjust_lr()\n",
        "            loss, ppl, acc = self.train_step(epoch, grad_clip, tf_ratio)\n",
        "            val_loss, val_ppl, val_acc = self.validate(epoch)\n",
        "            tf_ratio = self.adjust_tf(tf_ratio)\n",
        "            \n",
        "            if best_loss > val_loss:\n",
        "                best_loss, last_improv = val_loss, 0\n",
        "                torch.save(self.model.state_dict(), 'seq2seq.pth')\n",
        "            else:\n",
        "                last_improv += 1\n",
        "                print(f'Last improvement since epoch {epoch - last_improv + 1}')\n",
        "            \n",
        "            history['acc'].append(acc)\n",
        "            history['ppl'].append(ppl)\n",
        "            history['loss'].append(loss)\n",
        "            history['val_acc'].append(val_acc)\n",
        "            history['val_ppl'].append(val_ppl)\n",
        "            history['val_loss'].append(val_loss)\n",
        "        return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adURzNzWkthV"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B9ghlNzJkrCH"
      },
      "outputs": [],
      "source": [
        "#hyper-params\n",
        "N_LAYERS = 2\n",
        "HIDDEN_SIZE = 256\n",
        "EMBED_SIZE = 300\n",
        "EMBED_DROPOUT = 0.25\n",
        "REC_DROPOUT = 0.25\n",
        "N_EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "LR = 1e-3\n",
        "GRAD_CLIP = 1.0\n",
        "TF_RATIO = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3N7Sttcdk39H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d726d3-61b4-47d6-e311-308f453cf7db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters of the model: 10,883,303\n",
            "SeqToSeqNet(\n",
            "  (encoder): EncoderLayer(\n",
            "    (embedding): Embedding(10438, 300)\n",
            "    (gru): GRU(300, 256, num_layers=2, dropout=0.25, bidirectional=True)\n",
            "  )\n",
            "  (decoder): DecoderLayer(\n",
            "    (embedding): Embedding(8777, 300)\n",
            "    (gru): GRU(300, 256, num_layers=2, dropout=0.25)\n",
            "    (fc): Linear(in_features=256, out_features=8777, bias=True)\n",
            "  )\n",
            "  (init_h0): Linear(in_features=4, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "encoder = EncoderLayer(vocab_size=len(FR_TEXT.vocab), embedding_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, n_layers=N_LAYERS,\n",
        "                       embedding_dropout=EMBED_DROPOUT, recurrent_dropout=REC_DROPOUT)\n",
        "decoder = DecoderLayer(vocab_size=len(EN_TEXT.vocab), embedding_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, n_layers=N_LAYERS,\n",
        "                       embedding_dropout=EMBED_DROPOUT, recurrent_dropout=REC_DROPOUT)\n",
        "seq2seq = SeqToSeqNet(encoder=encoder, decoder=decoder, device=DEVICE).to(DEVICE)\n",
        "optimizer = optim.RMSprop(params=seq2seq.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(f'Number of parameters of the model: {sum(p.numel() for p in seq2seq.parameters() if p.requires_grad):,}')\n",
        "print(seq2seq)\n",
        "train_iterator, valid_iterator, test_iterator =  BucketIterator.splits((train, valid, test),\n",
        "                                                                       batch_size=BATCH_SIZE,\n",
        "                                                                       sort_key=lambda x: len(x.src),\n",
        "                                                                       sort_within_batch=True, device=DEVICE)\n",
        "trainer = Trainer(model=seq2seq, optimizer=optimizer, criterion=criterion, train_iterator=train_iterator, valid_iterator=valid_iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "isE439WfmDJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804906ff-f2e5-4290-ff3d-eb658fa145f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 01 -     loss: 5.805 -     ppl: 331.880 -     acc: 3.597%: 100%|██████████| 466/466 [00:33<00:00, 14.11it/s]\n",
            "Epoch: 01 - val_loss: 5.440 - val_ppl: 230.531 - val_acc: 4.018%: 100%|██████████| 16/16 [00:00<00:00, 28.68it/s]\n",
            "Epoch: 02 -     loss: 5.308 -     ppl: 201.926 -     acc: 4.171%: 100%|██████████| 466/466 [00:33<00:00, 14.10it/s]\n",
            "Epoch: 02 - val_loss: 5.181 - val_ppl: 177.791 - val_acc: 4.347%: 100%|██████████| 16/16 [00:00<00:00, 29.27it/s]\n",
            "Epoch: 03 -     loss: 4.993 -     ppl: 147.335 -     acc: 4.476%: 100%|██████████| 466/466 [00:32<00:00, 14.19it/s]\n",
            "Epoch: 03 - val_loss: 4.956 - val_ppl: 142.071 - val_acc: 4.721%: 100%|██████████| 16/16 [00:00<00:00, 29.28it/s]\n",
            "Epoch: 04 -     loss: 4.699 -     ppl: 109.879 -     acc: 4.765%: 100%|██████████| 466/466 [00:33<00:00, 14.11it/s]\n",
            "Epoch: 04 - val_loss: 4.778 - val_ppl: 118.870 - val_acc: 5.031%: 100%|██████████| 16/16 [00:00<00:00, 28.94it/s]\n",
            "Epoch: 05 -     loss: 4.443 -     ppl: 84.998 -     acc: 5.030%: 100%|██████████| 466/466 [00:32<00:00, 14.23it/s]\n",
            "Epoch: 05 - val_loss: 4.691 - val_ppl: 108.999 - val_acc: 5.213%: 100%|██████████| 16/16 [00:00<00:00, 29.50it/s]\n",
            "Epoch: 06 -     loss: 4.202 -     ppl: 66.831 -     acc: 5.333%: 100%|██████████| 466/466 [00:32<00:00, 14.23it/s]\n",
            "Epoch: 06 - val_loss: 4.651 - val_ppl: 104.650 - val_acc: 5.345%: 100%|██████████| 16/16 [00:00<00:00, 29.65it/s]\n",
            "Epoch: 07 -     loss: 3.999 -     ppl: 54.547 -     acc: 5.612%: 100%|██████████| 466/466 [00:32<00:00, 14.13it/s]\n",
            "Epoch: 07 - val_loss: 4.624 - val_ppl: 101.949 - val_acc: 5.490%: 100%|██████████| 16/16 [00:00<00:00, 28.77it/s]\n",
            "Epoch: 08 -     loss: 3.796 -     ppl: 44.536 -     acc: 5.925%: 100%|██████████| 466/466 [00:33<00:00, 13.99it/s]\n",
            "Epoch: 08 - val_loss: 4.592 - val_ppl: 98.684 - val_acc: 5.514%: 100%|██████████| 16/16 [00:00<00:00, 29.66it/s]\n",
            "Epoch: 09 -     loss: 3.653 -     ppl: 38.579 -     acc: 6.155%: 100%|██████████| 466/466 [00:32<00:00, 14.26it/s]\n",
            "Epoch: 09 - val_loss: 4.587 - val_ppl: 98.153 - val_acc: 5.613%: 100%|██████████| 16/16 [00:00<00:00, 29.74it/s]\n",
            "Epoch: 10 -     loss: 3.500 -     ppl: 33.132 -     acc: 6.429%: 100%|██████████| 466/466 [00:32<00:00, 14.20it/s]\n",
            "Epoch: 10 - val_loss: 4.564 - val_ppl: 95.979 - val_acc: 5.662%: 100%|██████████| 16/16 [00:00<00:00, 29.15it/s]\n"
          ]
        }
      ],
      "source": [
        "history = trainer.train(n_epochs=N_EPOCHS, grad_clip=GRAD_CLIP, tf_ratio=TF_RATIO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "t-8rAeqiqjd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "fc5263f7-6016-40bb-d363-96b3a6dee1e0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "_, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].plot(history['loss'], label='train')\n",
        "axes[0].plot(history['val_loss'], label='valid')\n",
        "axes[0].set_title('Loss history')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].grid(True)\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(history['ppl'], label='train')\n",
        "axes[1].plot(history['val_ppl'], label='valid')\n",
        "axes[1].set_title('Perplexity history')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Perplexity')\n",
        "axes[1].grid(True)\n",
        "axes[1].legend()\n",
        "\n",
        "axes[2].plot(history['acc'], label='train')\n",
        "axes[2].plot(history['val_acc'], label='valid')\n",
        "axes[2].set_title('Top-5 Accuracy & BLEU-4 history')\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].set_ylabel('Accuracy & BLEU-4 (%)')\n",
        "axes[2].grid(True)\n",
        "axes[2].legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIqN5273qP0L"
      },
      "source": [
        "# Evaluation "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beam search & BLEU score"
      ],
      "metadata": {
        "id": "dSPH8vZYkb5O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PPgXr4ii_MD9"
      },
      "outputs": [],
      "source": [
        "#find the best path + defining Node\n",
        "def find_path(tree):\n",
        "    path = []\n",
        "    for nodes in reversed(tree):\n",
        "        if len(path) == 0:\n",
        "            path.append(nodes[0])\n",
        "        else:\n",
        "            parent_id = path[-1].parent_id\n",
        "            for node in nodes:\n",
        "                if node.id == parent_id:\n",
        "                    path.append(node)\n",
        "    return path\n",
        "\n",
        "def find_best_path(tree):\n",
        "    best = []\n",
        "    for nodes in reversed(tree):\n",
        "        if len(best) == 0:\n",
        "            best.append(nodes[0])\n",
        "        else:\n",
        "            nodes_eos = []\n",
        "            parent_id = best[-1].parent_id\n",
        "            for node in nodes:\n",
        "                if node.eos:\n",
        "                    nodes_eos.append(node)\n",
        "                if node.id == parent_id:\n",
        "                    best.append(node)\n",
        "            if len(nodes_eos) > 0:\n",
        "                candidates = sorted([best[-1], *nodes_eos],\n",
        "                                    key=lambda node: node.logps,\n",
        "                                    reverse=True)\n",
        "                candidate = candidates[0]\n",
        "                if candidate.eos:\n",
        "                    best = [candidate]\n",
        "    return best\n",
        "\n",
        "class Node:\n",
        "    id_ = 0\n",
        "    \n",
        "    def __init__(self, token, states, logp=0., parent=None, eos=False):\n",
        "        self.__id = self.__class__.id_\n",
        "        self.__token = token\n",
        "        self.__states = states\n",
        "        self.__logp = logp\n",
        "        self.__parent_id = None if parent is None else parent.id\n",
        "        self.__eos = eos\n",
        "        self.__level = 0 if parent is None else parent.level + 1\n",
        "        self.__logps = logp if parent is None else parent.logps + logp\n",
        "        self.__class__.id_ += 1\n",
        "        \n",
        "    def __str__(self):\n",
        "        return f'Node[id={self.__id}, ' + \\\n",
        "                    f'index={EN.vocab.itos[self.__token.cpu().item()]}, ' + \\\n",
        "                    f'logp={self.__logp}, ' + \\\n",
        "                    f'logps={self.__logps}, ' + \\\n",
        "                    f'parent_id={self.__parent_id}, ' + \\\n",
        "                    f'level={self.__level}]'\n",
        "    \n",
        "    @property\n",
        "    def token(self):\n",
        "        return self.__token\n",
        "    \n",
        "    @token.setter\n",
        "    def token(self, token):\n",
        "        self.__token = token\n",
        "    \n",
        "    @property\n",
        "    def parent_id(self):\n",
        "        return self.__parent_id\n",
        "    \n",
        "    @parent_id.setter\n",
        "    def parent_id(self, parent_id):\n",
        "        self.__parent_id = parent_id\n",
        "        \n",
        "    @property\n",
        "    def id(self):\n",
        "        return self.__id\n",
        "    \n",
        "    @id.setter\n",
        "    def id(self, id_):\n",
        "        self.__id = id_\n",
        "    \n",
        "    @property\n",
        "    def token(self):\n",
        "        return self.__token\n",
        "    \n",
        "    @token.setter\n",
        "    def token(self, token):\n",
        "        self.__token = token\n",
        "    \n",
        "    @property\n",
        "    def states(self):\n",
        "        return self.__states\n",
        "    \n",
        "    @states.setter\n",
        "    def states(self, states):\n",
        "        self.__states = states\n",
        "      \n",
        "    @property\n",
        "    def eos(self):\n",
        "        return self.__eos\n",
        "    \n",
        "    @eos.setter\n",
        "    def eos(self, eos):\n",
        "        self.__eos = eos\n",
        "    \n",
        "    @property\n",
        "    def logps(self):\n",
        "        return self.__logps\n",
        "    \n",
        "    @logps.setter\n",
        "    def logps(self, logps):\n",
        "        self.__logps = logps\n",
        "        \n",
        "    @property\n",
        "    def level(self):\n",
        "        return self.__level\n",
        "    \n",
        "    @level.setter\n",
        "    def level(self, level):\n",
        "        self.__level = level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "axn3AumMmkvE"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data, beam_size, French_field, dest_field, max_len, device):\n",
        "    French_sentences = [*map(lambda example: example.French, data.examples)]\n",
        "    dest_sentences = [*map(lambda example: example.English, data.examples)]\n",
        "    data = [*zip([*map(lambda word_list: French_field.process([word_list]), French_sentences)],\n",
        "                 [*map(lambda word_list: dest_field.process([word_list]), dest_sentences)])]\n",
        "    references, hypotheses, sources = [], [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, ((French_sequence, French_length), (dest_sequence, dest_length)) in tqdm.tqdm(enumerate(data), total=len(data)):\n",
        "            French_sequence, French_length = French_sequence.to(device), French_length.to(device)\n",
        "            dest_sequence, dest_length = dest_sequence.to(device), dest_length.to(device)\n",
        "            \n",
        "            # Encoding\n",
        "            h_state = model.encoder(input_sequences=French_sequence, sequence_lengths=French_length) # Encode\n",
        "            h_state = model.init_h0(h_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
        "            h_state = h_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
        "\n",
        "            # Decoding\n",
        "            tree = [[Node(token=torch.LongTensor([dest_field.vocab.stoi[dest_field.init_token]]).to(device), states=(h_state,))]]\n",
        "            for _ in range(max_len):\n",
        "                next_nodes = []\n",
        "                for node in tree[-1]:\n",
        "                    if node.eos: # Skip eos token\n",
        "                        continue\n",
        "                    logit, h_state = model.decoder(input_word_index=node.token, h_state_prev=node.states[0].contiguous()) # Decode\n",
        "                    # logit: [1, vocab_size]\n",
        "                    # h_state: [n_layers, 1, hidden_size]\n",
        "                    # c_state: [n_layers, 1, hidden_size]\n",
        "\n",
        "                    logp = F.log_softmax(logit, dim=1).squeeze(dim=0) # [vocab_size] Get scores                    \n",
        "                    topk_logps, topk_tokens = torch.topk(logp, beam_size) # Get top k tokens & logps\n",
        "                    for k in range(beam_size):\n",
        "                        next_nodes.append(Node(token=topk_tokens[k, None], states=(h_state,),\n",
        "                                               logp=topk_logps[k, None].cpu().item(), parent=node,\n",
        "                                               eos=topk_tokens[k].cpu().item() == dest_field.vocab[dest_field.eos_token]))\n",
        "                if len(next_nodes) == 0:\n",
        "                    break\n",
        "                next_nodes = sorted(next_nodes, key=lambda node: node.logps, reverse=True) # Sort next_nodes to get the best\n",
        "                tree.append(next_nodes[:beam_size]) # Update the tree\n",
        "                \n",
        "            best_path = find_best_path(tree) # Find the best path of the tree\n",
        "\n",
        "            # Get the translation\n",
        "            pred_translated = [*map(lambda node: dest_field.vocab.itos[node.token], best_path)]\n",
        "            pred_translated = [*filter(lambda word: word not in [dest_field.init_token, dest_field.eos_token], pred_translated[::-1])]\n",
        "\n",
        "            hypotheses.append(pred_translated) # Update hypotheses\n",
        "\n",
        "            # Update references\n",
        "            references.append([[dest_field.vocab.itos[indice] for indice in dest_sequence if indice not in (\n",
        "                dest_field.vocab.stoi[dest_field.init_token],\n",
        "                dest_field.vocab.stoi[dest_field.eos_token],\n",
        "                dest_field.vocab.stoi[dest_field.pad_token]\n",
        "            )]])\n",
        "\n",
        "            # Update sources\n",
        "            sources.append([French_field.vocab.itos[indice]  for indice in French_sequence  if indice not in (\n",
        "                French_field.vocab.stoi[French_field.init_token],\n",
        "                French_field.vocab.stoi[French_field.eos_token],\n",
        "                French_field.vocab.stoi[French_field.pad_token]\n",
        "            )])\n",
        "    \n",
        "        assert len(hypotheses) == len(references) == len(sources)\n",
        "        bleu4 = bleu_score(hypotheses, references, max_n=4, weights=[0.25, 0.25, 0.25, 0.25]) # Calculate BLEU-4 score\n",
        "    return hypotheses, references, sources, bleu4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data, beam_size, src_field, dest_field, max_len, device):\n",
        "    src_sentences = [*map(lambda example: example.src, data.examples)]\n",
        "    dest_sentences = [*map(lambda example: example.trg, data.examples)]\n",
        "    data = [*zip([*map(lambda word_list: src_field.process([word_list]), src_sentences)],\n",
        "                 [*map(lambda word_list: dest_field.process([word_list]), dest_sentences)])]\n",
        "    references, hypotheses, sources = [], [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, ((src_sequence, src_length), (dest_sequence, dest_length)) in tqdm.tqdm(enumerate(data), total=len(data)):\n",
        "            src_sequence, src_length = src_sequence.to(device), src_length.to(device)\n",
        "            dest_sequence, dest_length = dest_sequence.to(device), dest_length.to(device)\n",
        "            \n",
        "            # Encoding\n",
        "            h_state = model.encoder(input_sequences=src_sequence, sequence_lengths=src_length) # Encode\n",
        "            h_state = model.init_h0(h_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
        "            h_state = h_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
        "\n",
        "            # Decoding\n",
        "            tree = [[Node(token=torch.LongTensor([dest_field.vocab.stoi[dest_field.init_token]]).to(device), states=(h_state,))]]\n",
        "            for _ in range(max_len):\n",
        "                next_nodes = []\n",
        "                for node in tree[-1]:\n",
        "                    if node.eos: # Skip eos token\n",
        "                        continue\n",
        "                    logit, h_state = model.decoder(input_word_index=node.token, h_state_prev=node.states[0].contiguous()) # Decode\n",
        "                    # logit: [1, vocab_size]\n",
        "                    # h_state: [n_layers, 1, hidden_size]\n",
        "                    # c_state: [n_layers, 1, hidden_size]\n",
        "\n",
        "                    logp = F.log_softmax(logit, dim=1).squeeze(dim=0) # [vocab_size] Get scores                    \n",
        "                    topk_logps, topk_tokens = torch.topk(logp, beam_size) # Get top k tokens & logps\n",
        "                    for k in range(beam_size):\n",
        "                        next_nodes.append(Node(token=topk_tokens[k, None], states=(h_state,),\n",
        "                                               logp=topk_logps[k, None].cpu().item(), parent=node,\n",
        "                                               eos=topk_tokens[k].cpu().item() == dest_field.vocab[dest_field.eos_token]))\n",
        "                if len(next_nodes) == 0:\n",
        "                    break\n",
        "                next_nodes = sorted(next_nodes, key=lambda node: node.logps, reverse=True) # Sort next_nodes to get the best\n",
        "                tree.append(next_nodes[:beam_size]) # Update the tree\n",
        "                \n",
        "            best_path = find_best_path(tree) # Find the best path of the tree\n",
        "\n",
        "            # Get the translation\n",
        "            pred_translated = [*map(lambda node: dest_field.vocab.itos[node.token], best_path)]\n",
        "            pred_translated = [*filter(lambda word: word not in [dest_field.init_token, dest_field.eos_token], pred_translated[::-1])]\n",
        "\n",
        "            hypotheses.append(pred_translated) # Update hypotheses\n",
        "\n",
        "            # Update references\n",
        "            references.append([[dest_field.vocab.itos[indice] for indice in dest_sequence if indice not in (\n",
        "                dest_field.vocab.stoi[dest_field.init_token],\n",
        "                dest_field.vocab.stoi[dest_field.eos_token],\n",
        "                dest_field.vocab.stoi[dest_field.pad_token]\n",
        "            )]])\n",
        "\n",
        "            # Update sources\n",
        "            sources.append([src_field.vocab.itos[indice]  for indice in src_sequence  if indice not in (\n",
        "                src_field.vocab.stoi[src_field.init_token],\n",
        "                src_field.vocab.stoi[src_field.eos_token],\n",
        "                src_field.vocab.stoi[src_field.pad_token]\n",
        "            )])\n",
        "    \n",
        "        assert len(hypotheses) == len(references) == len(sources)\n",
        "        bleu4 = bleu_score(hypotheses, references, max_n=4, weights=[0.25, 0.25, 0.25, 0.25]) # Calculate BLEU-4 score\n",
        "    return hypotheses, references, sources, bleu4"
      ],
      "metadata": {
        "id": "qEhLBJWG0Xmj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "g-lc-nLat-gI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7486c1a8-7902-43c5-9709-fa0b4cbb386e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SeqToSeqNet(\n",
              "  (encoder): EncoderLayer(\n",
              "    (embedding): Embedding(10438, 300)\n",
              "    (gru): GRU(300, 256, num_layers=2, dropout=0.25, bidirectional=True)\n",
              "  )\n",
              "  (decoder): DecoderLayer(\n",
              "    (embedding): Embedding(8777, 300)\n",
              "    (gru): GRU(300, 256, num_layers=2, dropout=0.25)\n",
              "    (fc): Linear(in_features=256, out_features=8777, bias=True)\n",
              "  )\n",
              "  (init_h0): Linear(in_features=4, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "seq2seq.load_state_dict(torch.load('seq2seq.pth'))\n",
        "seq2seq.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_scores = []\n",
        "for beam_size in [1, 3, 5]:\n",
        "    for name, data in [('validation', valid), ('test', test)]:\n",
        "        _, _, _, bleu4 = evaluate(model=seq2seq, data=data, beam_size=beam_size, src_field=FR_TEXT, dest_field=EN_TEXT, max_len=50, device=DEVICE)\n",
        "        bleu_scores.append((beam_size, name, bleu4))\n",
        "        \n",
        "for bleu_score in bleu_scores:\n",
        "    print(f'BLEU-4: {bleu_score[2]*100:.3f}% with beam_size={bleu_score[0]} on {bleu_score[1]} data')"
      ],
      "metadata": {
        "id": "VAW5R1E6z3Pu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ebcfaa7-e59a-4e55-fe84-587cf47f66a1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 996/996 [00:09<00:00, 101.66it/s]\n",
            "100%|██████████| 987/987 [00:09<00:00, 101.95it/s]\n",
            "100%|██████████| 996/996 [00:49<00:00, 20.06it/s]\n",
            "100%|██████████| 987/987 [00:49<00:00, 19.86it/s]\n",
            "100%|██████████| 996/996 [01:43<00:00,  9.63it/s]\n",
            "100%|██████████| 987/987 [01:42<00:00,  9.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-4: 5.933% with beam_size=1 on validation data\n",
            "BLEU-4: 6.407% with beam_size=1 on test data\n",
            "BLEU-4: 6.581% with beam_size=3 on validation data\n",
            "BLEU-4: 6.411% with beam_size=3 on test data\n",
            "BLEU-4: 6.630% with beam_size=5 on validation data\n",
            "BLEU-4: 6.598% with beam_size=5 on test data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQvQiVINwb_e"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "euSkrQikvFU4"
      },
      "outputs": [],
      "source": [
        "def translate(sentences, model, beam_size, src_field, dest_field, max_len, device):\n",
        "    if isinstance(sentences, list):\n",
        "        sentences = [*map(src_field.preprocess, sentences)]\n",
        "        targets = None\n",
        "    if isinstance(sentences, Dataset):\n",
        "        targets = [*map(lambda example: ' '.join(example.trg), sentences.examples)]\n",
        "        sentences = [*map(lambda example: example.src, sentences.examples)]\n",
        "    data = [*map(lambda word_list: src_field.process([word_list]), sentences)]\n",
        "    translated_sentences, pred_logps = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (src_sequence, src_length) in tqdm.tqdm(enumerate(data), total=len(data)):\n",
        "            src_sequence, src_length = src_sequence.to(device), src_length.to(device)\n",
        "            h_state = model.encoder(input_sequences=src_sequence, sequence_lengths=src_length) # Encode\n",
        "            h_state = model.init_h0(h_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
        "            h_state = h_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
        "            tree = [[Node(token=torch.LongTensor([dest_field.vocab.stoi[dest_field.init_token]]).to(device), states=(h_state,))]]\n",
        "            for _ in range(max_len):\n",
        "                next_nodes = []\n",
        "                for node in tree[-1]:\n",
        "                    if node.eos: # Skip eos token\n",
        "                        continue\n",
        "                    logit, h_state = model.decoder(input_word_index=node.token, h_state_prev=node.states[0].contiguous())\n",
        "                    logp = F.log_softmax(logit, dim=1).squeeze(dim=0)                   \n",
        "                    topk_logps, topk_tokens = torch.topk(logp, beam_size)\n",
        "                    for k in range(beam_size):\n",
        "                        next_nodes.append(Node(token=topk_tokens[k, None], states=(h_state,),\n",
        "                                               logp=topk_logps[k, None].cpu().item(), parent=node,\n",
        "                                               eos=topk_tokens[k].cpu().item() == dest_field.vocab[dest_field.eos_token]))\n",
        "                if len(next_nodes) == 0:\n",
        "                    break\n",
        "                next_nodes = sorted(next_nodes, key=lambda node: node.logps, reverse=True)\n",
        "                tree.append(next_nodes[:beam_size])\n",
        "            best_path = find_best_path(tree)\n",
        "            # Get the translation\n",
        "            pred_translated = [*map(lambda node: dest_field.vocab.itos[node.token], best_path)]\n",
        "            pred_translated = [*filter(lambda word: word not in [\n",
        "                dest_field.init_token, dest_field.eos_token\n",
        "            ], pred_translated[::-1])]\n",
        "            translated_sentences.append(' '.join(pred_translated))\n",
        "            # Get probabilities\n",
        "            pred_logps.append(sum([*map(lambda node: node.logps, best_path)]))\n",
        "        sentences = [*map(lambda sentence: ' '.join(sentence), sentences)]\n",
        "    return sentences, translated_sentences, targets, pred_logps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "uA8qEvYtzZn0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "outputId": "44f9ac9d-f16e-4090-fb98-ee3bbc433ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 987/987 [01:39<00:00,  9.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[800 971  66 263 792 770 475 542  10 423]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span style=\"color:black\"><b>Source:</b> madame le president chers collegues il agit assurement d un de premiere importance sur un sujet des plus serieux sans nul doute</span><br /><span style=\"color:black\"><b>Ground truth translation:</b> madam president ladies and gentlemen this is surely an extremely important report on what is without doubt a serious issue</span><br /><span style=\"color:pink\"><b>Predicted translation:</b> madam president ladies and gentlemen there is a major debate on an important importance of another importance</span></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span style=\"color:black\"><b>Source:</b> et nous devons une partie de notre l unite de vue des institutions</span><br /><span style=\"color:black\"><b>Ground truth translation:</b> if we succeeded it is due in part to the unity of purpose demonstrated by the various institutions</span><br /><span style=\"color:pink\"><b>Predicted translation:</b> and we should have part of our part of our part of our institutions</span></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span style=\"color:black\"><b>Source:</b> qu attendezvous de la suede et de finlande jusqu en en matiere d harmonisation impots indirects</span><br /><span style=\"color:black\"><b>Ground truth translation:</b> what expectations do you have of finland and sweden in relation to the harmonisation of indirect taxes by</span><br /><span style=\"color:pink\"><b>Predicted translation:</b> what airports <unk> <unk> and <unk> and <unk> studies has happened to <unk></span></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span style=\"color:black\"><b>Source:</b> nous ne devons prendre de decision hative a ce sujet</span><br /><span style=\"color:black\"><b>Ground truth translation:</b> it is a question of not making a hasty decision</span><br /><span style=\"color:pink\"><b>Predicted translation:</b> we need to take this eye on this matter</span></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span style=\"color:black\"><b>Source:</b> la raison pour laquelle nous n avons pas estime pouvoir declarer recevables ces amendements</span><br /><span style=\"color:black\"><b>Ground truth translation:</b> that is why we did not feel that we could deem these amendments to be acceptable</span><br /><span style=\"color:pink\"><b>Predicted translation:</b> the reason reason therefore therefore we are unable to accept these amendments</span></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span style=\"color:black\"><b>Source:</b> nous savons tous aussi le degre de sagesse elle y a apporte</span><br /><span style=\"color:black\"><b>Ground truth translation:</b> all of us know the amount of wisdom that went into it as well</span><br /><span style=\"color:pink\"><b>Predicted translation:</b> we all know that the picture of the picture of the council</span></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span style=\"color:black\"><b>Source:</b> la democratie c de l ouverture de la transparence des pouvoirs du peuple et la participation</span><br /><span style=\"color:black\"><b>Ground truth translation:</b> democracy is transparency public accessibility rule by the people and participation</span><br /><span style=\"color:pink\"><b>Predicted translation:</b> the effectiveness of the effectiveness of the effectiveness of the legitimacy and the of the european union</span></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span style=\"color:black\"><b>Source:</b> etats membres neutres ne souhaitent pas que l union se transforme en une et en une grande puissance militaires</span><br /><span style=\"color:black\"><b>Ground truth translation:</b> nonaligned member states do not want the union to become a military alliance or military superpower</span><br /><span style=\"color:pink\"><b>Predicted translation:</b> enlargement states do not need to do the european union and a <unk></span></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span style=\"color:black\"><b>Source:</b> madame la m vidalquadras roca a recolte semaine et nous avec lui les fruits du dialogue</span><br /><span style=\"color:black\"><b>Ground truth translation:</b> madam president this week mr vidalquadras roca has reaped the benefits of the dialogue as have we</span><br /><span style=\"color:pink\"><b>Predicted translation:</b> madam shall see you very much mr nielson we will engage with the debate with the negotiating authorities</span></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p><span style=\"color:black\"><b>Source:</b> avant de passer aux representant les groupes je donne la parole a m commissaire barnier</span><br /><span style=\"color:black\"><b>Ground truth translation:</b> before hearing the speakers for the groups i would like to give the floor to commissioner barnier</span><br /><span style=\"color:pink\"><b>Predicted translation:</b> before the rest of the i support mr solana to the commission</span></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "sentences, translated_sentences, dest_sentences, pred_logps = translate(sentences=test, model=seq2seq, beam_size=5, src_field=FR_TEXT,\n",
        "                                                                        dest_field=EN_TEXT, max_len=50, device=DEVICE)\n",
        "indexes = np.random.choice(len(test.examples), size=10, replace=False)\n",
        "print(indexes)\n",
        "print()\n",
        "for i in indexes:\n",
        "    html = f'<p><span style=\"color:black\"><b>Source:</b> {sentences[i]}</span><br />'\n",
        "    html += f'<span style=\"color:black\"><b>Ground truth translation:</b> {dest_sentences[i]}</span><br />'\n",
        "    html += f'<span style=\"color:pink\"><b>Predicted translation:</b> {translated_sentences[i]}</span></p>'\n",
        "    display(HTML(html))\n",
        "    print('='*100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "5_noise_seq2seq_RNN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}